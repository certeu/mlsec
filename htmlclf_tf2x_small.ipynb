{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"htmlclf_tf2x_small.ipynb","provenance":[{"file_id":"1ZUsQgInmwinizAql9dj0w9_s_90KrDHz","timestamp":1571130534556},{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/beginner.ipynb","timestamp":1555437903831}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hH1UdadsrlGM","colab_type":"text"},"source":["# Neural network malsite detector with TensorFlow, 30.5.2020"]},{"cell_type":"code","metadata":{"id":"QTpmZQtVLIo_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)\n","base_dir = \"gdrive/My Drive/Colab Notebooks/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"40fg_XzLLcaQ","colab_type":"code","colab":{}},"source":["!mkdir -p data\n","!tar -xzf gdrive/My\\ Drive/Colab\\ Notebooks/Data/htmldata.tar.gz -C data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAj1dMac7C08","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"kjh_RouvVZR8","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUydVCaMKlQa","colab_type":"code","colab":{}},"source":["import os, re, time,datetime\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Sz7_1UjBCr2","colab_type":"text"},"source":["#Feature extraction"]},{"cell_type":"code","metadata":{"id":"XM4_Uk5QCIt8","colab_type":"code","colab":{}},"source":["!pip install murmurhash3\n","import mmh3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"axqF_txPBIpt","colab_type":"code","colab":{}},"source":["def extract_features(string, hash_dim = 1024, split_regex = rb\"\\s+\"):\n","  tokens = re.split(pattern= split_regex, string = string)\n","  token_hash_buckets = [(mmh3.hash(w) % hash_dim) for w in tokens]\n","  buckets, counts = np.unique(token_hash_buckets,return_counts= True)\n","  token_hash_counts = np.zeros(hash_dim)\n","  for bucket, count in zip(buckets, counts):\n","    token_hash_counts[bucket] = count\n","  return token_hash_counts                       "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZi1meyoyAOP","colab_type":"text"},"source":["#Data generation"]},{"cell_type":"code","metadata":{"id":"TqYyY1mLM-Az","colab_type":"code","colab":{}},"source":["def read_file(file_name, dir):\n","  with open(os.path.join(dir, file_name),  'rb') as f:\n","    file = f.read()\n","  return file"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxPdLY7aWxm9","colab_type":"code","colab":{}},"source":["def my_generator(path_to_b_files, path_to_m_files, batch_size, features_size=1024):\n","  while True:\n","    b_files = os.listdir(path_to_b_files)\n","    m_files = os.listdir(path_to_m_files)\n","    n_samples_per_class = batch_size//2 # 2 = no. of classes\n","    assert len(b_files) >= n_samples_per_class\n","    assert len(m_files) >= n_samples_per_class\n","    b_features = [extract_features(read_file(file_name=sha, dir= path_to_b_files), hash_dim = features_size) for sha in np.random.choice(b_files, n_samples_per_class, replace = False) ]\n","    m_features = [extract_features(read_file(file_name=sha, dir= path_to_m_files), hash_dim = features_size) for sha in np.random.choice(m_files, n_samples_per_class, replace = False) ]\n","    all_features = b_features + m_features\n","    labels = [0 for i in range(n_samples_per_class)] + [1 for i in range(n_samples_per_class)]\n","    idx = np.random.choice(range(batch_size),batch_size)\n","    all_features = np.array([all_features[i] for i in idx])\n","    labels = np.array([labels[i] for i in idx])\n","    yield all_features, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2TSYCoqZmQf","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 128\n","FEATURES_SIZE = 1024\n","\n","path_to_training_b_files = 'data/html/benign_files/training/'\n","path_to_training_m_files = 'data/html/malicious_files/training/'\n","\n","train_b_files = os.listdir(path_to_training_b_files)\n","train_m_files = os.listdir(path_to_training_m_files)\n","\n","# Number of samples\n","nbr = len(train_b_files) + len(train_m_files)\n","print(nbr)\n","# Get number of training steps. This indicated the number of steps it takes\n","# to cover all samples in one epoch.\n","steps_per_epoch = nbr // BATCH_SIZE\n","if nbr % BATCH_SIZE:\n","    steps_per_epoch += 1\n","print(steps_per_epoch)\n","\n","training_generator = my_generator(\n","    path_to_b_files = path_to_training_b_files, \n","    path_to_m_files = path_to_training_m_files, \n","    batch_size = BATCH_SIZE, \n","    features_size = FEATURES_SIZE\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmcDkvQ1ZUkH","colab_type":"code","colab":{}},"source":["path_to_validation_b_files = 'data/html/benign_files/validation/'\n","path_to_validation_m_files = 'data/html/malicious_files/validation/'\n","\n","val_b_files = os.listdir(path_to_validation_b_files)\n","val_m_files = os.listdir(path_to_validation_m_files)\n","\n","nbr = len(val_b_files) + len(val_m_files)\n","print(nbr)\n","validation_steps = nbr // BATCH_SIZE\n","if nbr % BATCH_SIZE:\n","    validation_steps += 1\n","print(validation_steps)\n","\n","validation_generator = my_generator(\n","    path_to_b_files = path_to_validation_b_files, \n","    path_to_m_files = path_to_validation_m_files, \n","    batch_size = BATCH_SIZE, \n","    features_size= FEATURES_SIZE\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KpzB9F-DNNY9","colab_type":"text"},"source":["#Definition of the model"]},{"cell_type":"code","metadata":{"id":"oa6sNPWClEFC","colab_type":"code","colab":{}},"source":["def my_model(input_length=1024):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(1024, input_shape =(1024,), dtype='float32', activation='relu'),\n","    tf.keras.layers.BatchNormalization(),    \n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.BatchNormalization(), \n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.BatchNormalization(), \n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","  ])\n","  model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwo7_CgB_8aS","colab_type":"code","colab":{}},"source":["my_model().summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fU25TAcyphJd","colab_type":"text"},"source":["# Train the model"]},{"cell_type":"code","metadata":{"id":"P9j19AEdD4wL","colab_type":"code","colab":{}},"source":["start = time.time()\n","model = my_model(input_length = FEATURES_SIZE)\n","EPOCHS = 5\n","\n","history = model.fit(\n","    x= training_generator,\n","    y = None,\n","    steps_per_epoch= steps_per_epoch,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    epochs=EPOCHS,\n","    verbose=1\n",")\n","stop = time.time()\n","print(stop-start)"],"execution_count":0,"outputs":[]}]}